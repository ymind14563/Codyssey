{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. **통계 기반 추천 (Popularity-Based Recommendation)**\n",
    "\n",
    "### **알고리즘 원리**\n",
    "- 사용자의 행동 데이터를 기반으로 인기 있는 아이템을 계산.\n",
    "- 평점의 평균, 구매 횟수, 조회 수 등 특정 메트릭으로 상위 N개의 아이템을 추천.\n",
    "\n",
    "### **예시**\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# 데이터 예제: 사용자 행동\n",
    "data = pd.DataFrame({\n",
    "    'item_id': [1, 2, 1, 3, 2, 4],\n",
    "    'rating': [5, 4, 4, 5, 3, 2]\n",
    "})\n",
    "\n",
    "# 아이템별 평균 평점 계산\n",
    "popularity = data.groupby('item_id')['rating'].mean()\n",
    "\n",
    "# 상위 2개의 인기 아이템 추천\n",
    "top_items = popularity.nlargest(2)\n",
    "print(top_items)\n",
    "```\n",
    "\n",
    "\n",
    "## 2. **연관 규칙 학습 (Apriori Algorithm)**\n",
    "\n",
    "### **알고리즘 원리**\n",
    "1. **지지도(Support)**:\n",
    "   - 특정 아이템 집합이 전체 거래에서 등장한 비율.\n",
    "   - \\( \\text{Support}(A) = \\frac{\\text{거래 중 A가 포함된 횟수}}{\\text{전체 거래 수}} \\)\n",
    "2. **신뢰도(Confidence)**:\n",
    "   - 아이템 A가 포함된 거래 중 아이템 B도 포함될 확률.\n",
    "   - \\( \\text{Confidence}(A \\Rightarrow B) = \\frac{\\text{Support}(A \\cap B)}{\\text{Support}(A)} \\)\n",
    "3. **향상도(Lift)**:\n",
    "   - 두 아이템 간의 실제 상관관계를 평가.\n",
    "   - \\( \\text{Lift}(A \\Rightarrow B) = \\frac{\\text{Confidence}(A \\Rightarrow B)}{\\text{Support}(B)} \\)\n",
    "\n",
    "### **예시**\n",
    "```python\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "\n",
    "# 거래 데이터\n",
    "data = pd.DataFrame({\n",
    "    'milk': [1, 0, 1, 0, 1],\n",
    "    'bread': [1, 1, 1, 0, 1],\n",
    "    'butter': [0, 1, 0, 1, 1]\n",
    "})\n",
    "\n",
    "# 자주 등장하는 아이템 집합 찾기\n",
    "frequent_itemsets = apriori(data, min_support=0.5, use_colnames=True)\n",
    "\n",
    "# 연관 규칙 생성\n",
    "rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=0.7)\n",
    "print(rules)\n",
    "```\n",
    "\n",
    "\n",
    "## 3. **콘텐츠 기반 추천 (Content-Based Filtering)**\n",
    "\n",
    "### **알고리즘 원리**\n",
    "1. 아이템의 특징을 벡터로 표현 (예: TF-IDF, Word2Vec 등).\n",
    "2. 사용자가 선호한 아이템과 다른 아이템 간의 유사도를 계산.\n",
    "3. 가장 유사한 아이템을 추천.\n",
    "\n",
    "### **TF-IDF 활용**\n",
    "- **TF (Term Frequency)**: 특정 단어가 문서에서 등장한 빈도.\n",
    "- **IDF (Inverse Document Frequency)**: 단어가 전체 문서에서 얼마나 드문지를 나타냄.\n",
    "  \\[\n",
    "  \\text{TF-IDF}(t, d) = \\text{TF}(t, d) \\times \\log\\left(\\frac{N}{\\text{DF}(t)}\\right)\n",
    "  \\]\n",
    "\n",
    "### **예시**\n",
    "```python\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# 아이템과 장르 데이터\n",
    "items = ['Star Wars', 'Avengers', 'Inception']\n",
    "genres = ['Sci-Fi Adventure', 'Action Adventure', 'Sci-Fi Thriller']\n",
    "\n",
    "# TF-IDF로 장르를 벡터화\n",
    "vectorizer = TfidfVectorizer()\n",
    "genre_vectors = vectorizer.fit_transform(genres)\n",
    "\n",
    "# 아이템 간 코사인 유사도 계산\n",
    "cosine_sim = cosine_similarity(genre_vectors)\n",
    "print(cosine_sim)\n",
    "```\n",
    "\n",
    "\n",
    "## 4. **협업 필터링 (Collaborative Filtering)**\n",
    "\n",
    "### **알고리즘 원리**\n",
    "1. **사용자 기반**: 비슷한 행동을 보이는 사용자 그룹을 찾아 추천.\n",
    "   - \\( \\text{유사도} = \\text{코사인 유사도} \\, \\text{또는 피어슨 상관계수} \\)\n",
    "2. **아이템 기반**: 유사한 아이템을 찾고 이를 바탕으로 추천.\n",
    "\n",
    "### **코사인 유사도**\n",
    "\\[\n",
    "\\text{Cosine Similarity} = \\frac{\\mathbf{A} \\cdot \\mathbf{B}}{\\|\\mathbf{A}\\| \\|\\mathbf{B}\\|}\n",
    "\\]\n",
    "\n",
    "### **예시**\n",
    "```python\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# 사용자-아이템 평점 행렬\n",
    "ratings = np.array([\n",
    "    [5, 0, 3],\n",
    "    [4, 0, 0],\n",
    "    [1, 1, 0]\n",
    "])\n",
    "\n",
    "# 사용자 간 유사도 계산\n",
    "user_similarity = cosine_similarity(ratings)\n",
    "print(user_similarity)\n",
    "\n",
    "# 아이템 간 유사도 계산\n",
    "item_similarity = cosine_similarity(ratings.T)\n",
    "print(item_similarity)\n",
    "```\n",
    "\n",
    "\n",
    "## 5. **행렬 분해 (Matrix Factorization)**\n",
    "\n",
    "### **알고리즘 원리**\n",
    "- 사용자-아이템 평점 행렬 \\( R \\)을 분해:\n",
    "  \\[\n",
    "  R \\approx U \\Sigma V^T\n",
    "  \\]\n",
    "  - \\( U \\): 사용자 잠재 요인.\n",
    "  - \\( V^T \\): 아이템 잠재 요인.\n",
    "- **잠재 요인**: 사용자와 아이템의 숨겨진 관계를 학습.\n",
    "\n",
    "### **SVD 활용**\n",
    "```python\n",
    "from scipy.sparse.linalg import svds\n",
    "\n",
    "# 사용자-아이템 평점 행렬\n",
    "ratings = np.array([\n",
    "    [4, 0, 0, 5],\n",
    "    [5, 5, 0, 0],\n",
    "    [0, 0, 5, 4]\n",
    "])\n",
    "\n",
    "# SVD를 사용한 행렬 분해\n",
    "U, sigma, Vt = svds(ratings, k=2)\n",
    "sigma = np.diag(sigma)\n",
    "\n",
    "# 분해된 행렬로 예측\n",
    "predicted_ratings = np.dot(np.dot(U, sigma), Vt)\n",
    "print(predicted_ratings)\n",
    "```\n",
    "\n",
    "## 6. **딥러닝 기반 추천**\n",
    "\n",
    "### **Autoencoder 활용**\n",
    "- **원리**: 입력 데이터를 압축(인코딩)했다가 복원(디코딩)하며 특징을 학습.\n",
    "- **구조**: 입력층 → 숨겨진 층 (Latent Factors) → 출력층.\n",
    "\n",
    "### **예시**\n",
    "```python\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# 사용자-아이템 평점 행렬\n",
    "ratings = np.array([\n",
    "    [5, 0, 3],\n",
    "    [4, 0, 0],\n",
    "    [1, 1, 0]\n",
    "])\n",
    "\n",
    "# Autoencoder 모델 정의\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_dim=ratings.shape[1]),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(ratings.shape[1], activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "model.fit(ratings, ratings, epochs=50, verbose=0)\n",
    "predictions = model.predict(ratings)\n",
    "print(predictions)\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
